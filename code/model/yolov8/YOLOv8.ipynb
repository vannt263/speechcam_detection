{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.0.203)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.8.0.76)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (10.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (1.11.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\vannt\\appdata\\roaming\\python\\python311\\site-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vannt\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vannt\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.9.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vannt\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vannt\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vannt\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLOv8n model\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 225 layers, 3157200 parameters, 0 gradients, 8.9 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225, 3157200, 0, 8.8575488)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display model information (optional)\n",
    "model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\bus.jpg: 448x640 2 persons, 1 car, 1 bus, 558.7ms\n",
      "Speed: 8.5ms preprocess, 558.7ms inference, 15.6ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run inference with the YOLOv8n model on the 'bus.jpg' image\n",
    "results = model('../data/bus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " orig_img: array([[[170, 166, 171],\n",
       "         [176, 172, 177],\n",
       "         [176, 175, 179],\n",
       "         ...,\n",
       "         [157, 157, 157],\n",
       "         [148, 148, 148],\n",
       "         [139, 139, 139]],\n",
       " \n",
       "        [[ 91,  87,  92],\n",
       "         [ 99,  95, 100],\n",
       "         [106, 105, 109],\n",
       "         ...,\n",
       "         [153, 153, 153],\n",
       "         [169, 169, 169],\n",
       "         [180, 180, 180]],\n",
       " \n",
       "        [[ 26,  23,  25],\n",
       "         [ 30,  27,  29],\n",
       "         [ 32,  31,  33],\n",
       "         ...,\n",
       "         [222, 222, 222],\n",
       "         [223, 223, 223],\n",
       "         [224, 224, 224]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[107,  93,  87],\n",
       "         [110,  96,  90],\n",
       "         [111,  97,  91],\n",
       "         ...,\n",
       "         [128, 125, 117],\n",
       "         [127, 124, 116],\n",
       "         [121, 118, 110]],\n",
       " \n",
       "        [[107,  93,  87],\n",
       "         [105,  91,  85],\n",
       "         [104,  90,  84],\n",
       "         ...,\n",
       "         [129, 126, 118],\n",
       "         [127, 125, 115],\n",
       "         [122, 120, 110]],\n",
       " \n",
       "        [[114, 100,  94],\n",
       "         [108,  94,  88],\n",
       "         [105,  91,  85],\n",
       "         ...,\n",
       "         [114, 111, 103],\n",
       "         [124, 122, 112],\n",
       "         [134, 132, 122]]], dtype=uint8)\n",
       " orig_shape: (800, 1200)\n",
       " path: 'd:\\\\study\\\\computer_vision\\\\speechcam_detection\\\\yolov8\\\\..\\\\data\\\\bus.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 8.50987434387207, 'inference': 558.6843490600586, 'postprocess': 15.595674514770508}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1: 0... Success  (inf frames of shape 640x480 at 30.00 FPS)\n",
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "0: 480x640 1 person, 197.4ms\n",
      "0: 480x640 1 person, 214.0ms\n",
      "0: 480x640 1 person, 256.2ms\n",
      "0: 480x640 1 person, 280.7ms\n",
      "0: 480x640 1 person, 268.5ms\n",
      "0: 480x640 1 person, 277.8ms\n",
      "0: 480x640 1 person, 371.6ms\n",
      "0: 480x640 1 person, 293.0ms\n",
      "0: 480x640 1 person, 284.4ms\n",
      "0: 480x640 1 person, 273.1ms\n",
      "0: 480x640 1 person, 235.1ms\n",
      "0: 480x640 1 person, 229.0ms\n",
      "0: 480x640 1 person, 260.0ms\n",
      "0: 480x640 1 person, 241.9ms\n",
      "0: 480x640 1 person, 250.7ms\n",
      "0: 480x640 1 person, 261.2ms\n",
      "0: 480x640 1 person, 304.1ms\n",
      "0: 480x640 1 person, 360.5ms\n",
      "0: 480x640 1 person, 470.6ms\n",
      "0: 480x640 1 person, 367.6ms\n",
      "0: 480x640 1 person, 356.4ms\n",
      "0: 480x640 1 person, 465.9ms\n",
      "0: 480x640 1 person, 422.2ms\n",
      "0: 480x640 1 person, 369.6ms\n",
      "0: 480x640 1 person, 328.1ms\n",
      "0: 480x640 1 person, 554.6ms\n",
      "0: 480x640 1 person, 905.4ms\n",
      "0: 480x640 1 person, 1031.0ms\n",
      "0: 480x640 1 person, 2058.3ms\n",
      "0: 480x640 1 person, 1216.3ms\n",
      "0: 480x640 1 person, 982.6ms\n",
      "0: 480x640 1 person, 1432.7ms\n",
      "0: 480x640 1 person, 1145.3ms\n",
      "0: 480x640 1 person, 306.5ms\n",
      "0: 480x640 1 person, 306.9ms\n",
      "0: 480x640 1 person, 253.6ms\n",
      "0: 480x640 1 person, 213.4ms\n",
      "0: 480x640 1 person, 193.2ms\n",
      "0: 480x640 1 person, 196.4ms\n",
      "0: 480x640 1 person, 181.8ms\n",
      "0: 480x640 1 person, 210.3ms\n",
      "0: 480x640 1 person, 354.9ms\n",
      "0: 480x640 1 person, 303.6ms\n",
      "0: 480x640 1 person, 322.4ms\n",
      "0: 480x640 1 person, 279.2ms\n",
      "0: 480x640 1 person, 334.7ms\n",
      "0: 480x640 1 person, 295.4ms\n",
      "0: 480x640 2 persons, 502.3ms\n",
      "0: 480x640 1 person, 372.1ms\n",
      "0: 480x640 1 person, 348.4ms\n",
      "0: 480x640 1 person, 333.1ms\n",
      "0: 480x640 1 person, 280.9ms\n",
      "0: 480x640 1 person, 351.8ms\n",
      "0: 480x640 1 person, 309.3ms\n",
      "0: 480x640 1 person, 545.2ms\n",
      "0: 480x640 1 person, 306.4ms\n",
      "0: 480x640 1 person, 427.5ms\n",
      "0: 480x640 1 person, 304.3ms\n",
      "0: 480x640 1 person, 314.5ms\n",
      "0: 480x640 1 person, 292.0ms\n",
      "0: 480x640 1 person, 263.4ms\n",
      "0: 480x640 1 person, 273.9ms\n",
      "0: 480x640 1 person, 273.1ms\n",
      "0: 480x640 1 person, 422.0ms\n",
      "0: 480x640 1 person, 277.9ms\n",
      "0: 480x640 1 person, 245.8ms\n",
      "0: 480x640 1 person, 319.9ms\n",
      "0: 480x640 1 person, 301.8ms\n",
      "0: 480x640 1 person, 304.1ms\n",
      "0: 480x640 1 person, 284.0ms\n",
      "0: 480x640 1 person, 294.1ms\n",
      "0: 480x640 1 person, 298.3ms\n",
      "0: 480x640 1 person, 291.8ms\n",
      "0: 480x640 1 person, 302.3ms\n",
      "0: 480x640 1 person, 320.4ms\n",
      "0: 480x640 1 person, 251.8ms\n",
      "0: 480x640 1 person, 245.5ms\n",
      "0: 480x640 1 person, 271.7ms\n",
      "0: 480x640 1 person, 298.1ms\n",
      "0: 480x640 1 person, 296.7ms\n",
      "0: 480x640 1 person, 294.7ms\n",
      "0: 480x640 1 person, 271.3ms\n",
      "0: 480x640 1 person, 273.3ms\n",
      "0: 480x640 1 person, 344.8ms\n",
      "0: 480x640 1 person, 286.2ms\n",
      "0: 480x640 1 person, 353.1ms\n",
      "0: 480x640 1 person, 354.3ms\n",
      "0: 480x640 1 person, 322.4ms\n",
      "0: 480x640 1 person, 309.6ms\n",
      "0: 480x640 1 person, 320.6ms\n",
      "0: 480x640 1 person, 299.2ms\n",
      "0: 480x640 1 person, 313.0ms\n",
      "0: 480x640 1 person, 285.5ms\n",
      "0: 480x640 1 person, 337.5ms\n",
      "0: 480x640 1 person, 460.7ms\n",
      "0: 480x640 1 person, 344.3ms\n",
      "0: 480x640 1 person, 351.1ms\n",
      "0: 480x640 1 person, 448.1ms\n",
      "0: 480x640 1 person, 406.2ms\n",
      "0: 480x640 1 person, 311.1ms\n",
      "0: 480x640 (no detections), 339.8ms\n",
      "0: 480x640 (no detections), 326.4ms\n",
      "0: 480x640 (no detections), 358.4ms\n",
      "0: 480x640 (no detections), 342.4ms\n",
      "0: 480x640 1 person, 350.7ms\n",
      "0: 480x640 1 person, 341.4ms\n",
      "0: 480x640 1 person, 376.2ms\n",
      "0: 480x640 1 person, 367.0ms\n",
      "0: 480x640 1 person, 398.3ms\n",
      "0: 480x640 1 person, 441.9ms\n",
      "0: 480x640 1 person, 522.0ms\n",
      "0: 480x640 1 person, 476.3ms\n",
      "0: 480x640 1 person, 445.7ms\n",
      "0: 480x640 1 person, 533.2ms\n",
      "0: 480x640 1 person, 558.6ms\n",
      "0: 480x640 1 person, 431.7ms\n",
      "0: 480x640 1 person, 410.0ms\n",
      "0: 480x640 1 person, 413.5ms\n",
      "0: 480x640 1 person, 525.9ms\n",
      "0: 480x640 1 person, 444.9ms\n",
      "0: 480x640 1 person, 389.5ms\n",
      "0: 480x640 1 person, 386.2ms\n",
      "0: 480x640 1 person, 373.7ms\n",
      "0: 480x640 1 person, 380.4ms\n",
      "0: 480x640 1 person, 318.9ms\n",
      "0: 480x640 1 person, 246.2ms\n",
      "0: 480x640 1 person, 286.4ms\n",
      "0: 480x640 1 person, 282.8ms\n",
      "0: 480x640 1 person, 272.7ms\n",
      "0: 480x640 1 person, 299.3ms\n",
      "0: 480x640 1 person, 283.5ms\n",
      "0: 480x640 1 person, 279.6ms\n",
      "0: 480x640 1 person, 283.5ms\n",
      "0: 480x640 1 person, 286.8ms\n",
      "0: 480x640 1 person, 456.5ms\n",
      "0: 480x640 1 person, 389.7ms\n",
      "0: 480x640 1 person, 409.3ms\n",
      "0: 480x640 1 person, 390.6ms\n",
      "0: 480x640 1 person, 312.9ms\n",
      "0: 480x640 1 person, 324.3ms\n",
      "0: 480x640 1 person, 307.5ms\n",
      "0: 480x640 1 person, 339.6ms\n",
      "0: 480x640 1 person, 335.2ms\n",
      "0: 480x640 1 person, 334.4ms\n",
      "0: 480x640 1 person, 315.0ms\n",
      "0: 480x640 1 person, 325.8ms\n",
      "0: 480x640 1 person, 312.5ms\n",
      "0: 480x640 1 person, 336.2ms\n",
      "0: 480x640 1 person, 322.3ms\n",
      "0: 480x640 1 person, 320.8ms\n",
      "0: 480x640 1 person, 356.5ms\n",
      "0: 480x640 1 person, 357.9ms\n",
      "0: 480x640 1 person, 231.3ms\n",
      "0: 480x640 1 person, 256.0ms\n",
      "0: 480x640 1 person, 263.0ms\n",
      "0: 480x640 1 person, 651.1ms\n",
      "0: 480x640 1 person, 246.3ms\n",
      "0: 480x640 1 person, 248.9ms\n",
      "0: 480x640 1 person, 272.9ms\n",
      "0: 480x640 1 person, 261.2ms\n",
      "0: 480x640 1 person, 268.8ms\n",
      "0: 480x640 1 person, 229.6ms\n",
      "0: 480x640 1 person, 239.7ms\n",
      "0: 480x640 1 person, 255.1ms\n",
      "0: 480x640 1 person, 431.1ms\n",
      "0: 480x640 1 person, 357.4ms\n",
      "0: 480x640 1 person, 415.1ms\n",
      "0: 480x640 1 person, 436.8ms\n",
      "0: 480x640 1 person, 396.1ms\n",
      "0: 480x640 1 person, 388.3ms\n",
      "0: 480x640 1 person, 330.4ms\n",
      "0: 480x640 1 person, 381.1ms\n",
      "0: 480x640 1 person, 417.7ms\n",
      "0: 480x640 1 person, 410.7ms\n",
      "0: 480x640 1 person, 401.5ms\n",
      "0: 480x640 1 person, 396.5ms\n",
      "0: 480x640 1 person, 476.7ms\n",
      "0: 480x640 1 person, 445.4ms\n",
      "0: 480x640 1 person, 449.0ms\n",
      "0: 480x640 1 person, 506.2ms\n",
      "0: 480x640 1 person, 402.6ms\n",
      "0: 480x640 1 person, 470.9ms\n",
      "0: 480x640 1 person, 412.2ms\n",
      "0: 480x640 1 person, 348.3ms\n",
      "0: 480x640 1 person, 335.5ms\n",
      "0: 480x640 1 person, 337.2ms\n",
      "0: 480x640 1 person, 359.4ms\n",
      "0: 480x640 1 person, 313.1ms\n",
      "0: 480x640 1 person, 322.5ms\n",
      "0: 480x640 1 person, 462.2ms\n",
      "0: 480x640 1 person, 365.5ms\n",
      "0: 480x640 1 person, 485.8ms\n",
      "0: 480x640 1 person, 427.1ms\n",
      "0: 480x640 1 person, 279.2ms\n",
      "0: 480x640 1 person, 260.5ms\n",
      "0: 480x640 1 person, 509.9ms\n",
      "0: 480x640 1 person, 481.9ms\n",
      "0: 480x640 1 person, 347.9ms\n",
      "0: 480x640 1 person, 563.7ms\n",
      "0: 480x640 1 person, 512.9ms\n",
      "0: 480x640 1 person, 468.2ms\n",
      "0: 480x640 1 person, 569.9ms\n",
      "0: 480x640 1 person, 728.7ms\n",
      "0: 480x640 1 person, 609.2ms\n",
      "0: 480x640 1 person, 385.2ms\n",
      "0: 480x640 1 person, 551.5ms\n",
      "0: 480x640 1 person, 518.7ms\n",
      "0: 480x640 1 person, 525.0ms\n",
      "0: 480x640 1 person, 503.8ms\n",
      "0: 480x640 1 person, 317.9ms\n",
      "0: 480x640 2 persons, 749.6ms\n",
      "0: 480x640 1 person, 641.0ms\n",
      "0: 480x640 2 persons, 632.3ms\n",
      "0: 480x640 1 person, 594.7ms\n",
      "0: 480x640 1 person, 589.7ms\n",
      "0: 480x640 1 person, 438.1ms\n",
      "0: 480x640 1 person, 1004.0ms\n",
      "0: 480x640 1 person, 377.4ms\n",
      "0: 480x640 2 persons, 373.7ms\n",
      "0: 480x640 1 person, 304.2ms\n",
      "0: 480x640 2 persons, 521.4ms\n",
      "0: 480x640 2 persons, 339.5ms\n",
      "0: 480x640 1 person, 303.0ms\n",
      "0: 480x640 1 person, 327.1ms\n",
      "0: 480x640 1 person, 320.1ms\n",
      "0: 480x640 2 persons, 299.0ms\n",
      "0: 480x640 1 person, 317.7ms\n",
      "0: 480x640 1 person, 331.9ms\n",
      "0: 480x640 1 person, 267.6ms\n",
      "0: 480x640 1 person, 199.3ms\n",
      "0: 480x640 1 person, 181.7ms\n",
      "0: 480x640 1 person, 166.6ms\n",
      "0: 480x640 1 person, 201.9ms\n",
      "0: 480x640 1 person, 419.1ms\n",
      "0: 480x640 2 persons, 333.3ms\n",
      "0: 480x640 2 persons, 315.9ms\n",
      "0: 480x640 1 person, 292.7ms\n",
      "0: 480x640 1 person, 315.3ms\n",
      "0: 480x640 1 person, 305.7ms\n",
      "0: 480x640 1 person, 260.3ms\n",
      "0: 480x640 2 persons, 412.2ms\n",
      "0: 480x640 2 persons, 470.5ms\n",
      "0: 480x640 1 person, 378.8ms\n",
      "0: 480x640 1 person, 261.1ms\n",
      "0: 480x640 1 person, 290.3ms\n",
      "0: 480x640 1 person, 325.1ms\n",
      "0: 480x640 1 person, 317.8ms\n",
      "0: 480x640 1 person, 435.0ms\n",
      "0: 480x640 1 person, 324.4ms\n",
      "0: 480x640 1 person, 327.9ms\n",
      "0: 480x640 1 person, 241.2ms\n",
      "0: 480x640 1 person, 397.8ms\n",
      "0: 480x640 1 person, 330.1ms\n",
      "0: 480x640 1 person, 377.7ms\n",
      "0: 480x640 1 person, 518.0ms\n",
      "0: 480x640 1 person, 286.3ms\n",
      "0: 480x640 1 person, 301.6ms\n",
      "0: 480x640 1 person, 297.2ms\n",
      "0: 480x640 1 person, 280.1ms\n",
      "0: 480x640 1 person, 300.5ms\n",
      "0: 480x640 1 person, 341.9ms\n",
      "0: 480x640 1 person, 331.7ms\n",
      "0: 480x640 1 person, 318.0ms\n",
      "0: 480x640 1 person, 347.7ms\n",
      "0: 480x640 1 person, 457.8ms\n",
      "0: 480x640 1 person, 366.6ms\n",
      "0: 480x640 1 person, 321.2ms\n",
      "0: 480x640 1 person, 280.7ms\n",
      "0: 480x640 1 person, 287.1ms\n",
      "0: 480x640 1 person, 252.5ms\n",
      "0: 480x640 1 person, 278.1ms\n",
      "0: 480x640 1 person, 257.9ms\n",
      "0: 480x640 1 person, 270.4ms\n",
      "0: 480x640 1 person, 225.8ms\n",
      "0: 480x640 1 person, 271.6ms\n",
      "0: 480x640 2 persons, 314.8ms\n",
      "0: 480x640 1 person, 293.2ms\n",
      "0: 480x640 1 person, 292.1ms\n",
      "0: 480x640 1 person, 288.4ms\n",
      "0: 480x640 1 person, 236.2ms\n",
      "0: 480x640 1 person, 182.3ms\n",
      "0: 480x640 1 person, 186.1ms\n",
      "0: 480x640 1 person, 203.0ms\n",
      "0: 480x640 1 person, 340.2ms\n",
      "0: 480x640 1 person, 354.3ms\n",
      "0: 480x640 1 person, 319.1ms\n",
      "0: 480x640 1 person, 281.0ms\n",
      "0: 480x640 1 person, 279.5ms\n",
      "0: 480x640 2 persons, 245.6ms\n",
      "0: 480x640 1 person, 259.5ms\n",
      "0: 480x640 2 persons, 275.3ms\n",
      "0: 480x640 1 person, 336.1ms\n",
      "0: 480x640 1 person, 298.5ms\n",
      "0: 480x640 1 person, 408.5ms\n",
      "0: 480x640 1 person, 293.8ms\n",
      "0: 480x640 1 person, 283.4ms\n",
      "0: 480x640 1 person, 277.8ms\n",
      "0: 480x640 1 person, 258.6ms\n",
      "0: 480x640 1 person, 243.0ms\n",
      "0: 480x640 1 person, 258.3ms\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\computer_vision\\speechcam_detection\\yolov8\\YOLOv8.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study/computer_vision/speechcam_detection/yolov8/YOLOv8.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# run realtime using laptop's camera\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/study/computer_vision/speechcam_detection/yolov8/YOLOv8.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m model(source\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, show\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, conf\u001b[39m=\u001b[39;49m\u001b[39m0.4\u001b[39;49m, save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:101\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, source\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calls the 'predict' function with given arguments to perform object detection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(source, stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:242\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:196\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream_inference(source, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:56\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m             \u001b[39m# Pass the last request to the generator and get its response\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 56\u001b[0m                 response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(request)\n\u001b[0;32m     58\u001b[0m \u001b[39m# We let the exceptions raised above by the generator's `.throw` or\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# `.send` methods bubble up to our caller, except for StopIteration\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m     \u001b[39m# The generator informed us that it is done: take whatever its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[39m# returned value (if any) was and indicate that we're done too\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[39m# by returning it (see docs for python's return-statement).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:259\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39m# Inference\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m1\u001b[39m]:\n\u001b[1;32m--> 259\u001b[0m     preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minference(im, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    261\u001b[0m \u001b[39m# Postprocess\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39mwith\u001b[39;00m profilers[\u001b[39m2\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:135\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    133\u001b[0m visualize \u001b[39m=\u001b[39m increment_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mstem,\n\u001b[0;32m    134\u001b[0m                            mkdir\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mvisualize \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_type\u001b[39m.\u001b[39mtensor) \u001b[39melse\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im, augment\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49maugment, visualize\u001b[39m=\u001b[39;49mvisualize)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:347\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize)\u001b[0m\n\u001b[0;32m    344\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m)  \u001b[39m# torch BCHW to numpy BHWC shape(1,320,192,3)\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnn_module:  \u001b[39m# PyTorch\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im, augment\u001b[39m=\u001b[39maugment, visualize\u001b[39m=\u001b[39mvisualize) \u001b[39mif\u001b[39;00m augment \u001b[39mor\u001b[39;00m visualize \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(im)\n\u001b[0;32m    348\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjit:  \u001b[39m# TorchScript\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(im)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:42\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mdict\u001b[39m):  \u001b[39m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 42\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:59\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m augment:\n\u001b[0;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict_augment(x)\n\u001b[1;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict_once(x, profile, visualize)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:79\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mif\u001b[39;00m profile:\n\u001b[0;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m---> 79\u001b[0m x \u001b[39m=\u001b[39m m(x)  \u001b[39m# run\u001b[39;00m\n\u001b[0;32m     80\u001b[0m y\u001b[39m.\u001b[39mappend(x \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mi \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)  \u001b[39m# save output\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vannt\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:204\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    202\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv1(x)\u001b[39m.\u001b[39mchunk(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m    203\u001b[0m y\u001b[39m.\u001b[39mextend(m(y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm)\n\u001b[1;32m--> 204\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv2(torch\u001b[39m.\u001b[39;49mcat(y, \u001b[39m1\u001b[39;49m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# run realtime using laptop's camera\n",
    "results = model(source=0, show=True, conf=0.4, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (1/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 120.8ms\n",
      "video 1/1 (2/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 12 cars, 1 bus, 100.0ms\n",
      "video 1/1 (3/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 94.7ms\n",
      "video 1/1 (4/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 100.9ms\n",
      "video 1/1 (5/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 92.4ms\n",
      "video 1/1 (6/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 90.5ms\n",
      "video 1/1 (7/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 91.6ms\n",
      "video 1/1 (8/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 100.0ms\n",
      "video 1/1 (9/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 99.9ms\n",
      "video 1/1 (10/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 115.6ms\n",
      "video 1/1 (11/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 101.8ms\n",
      "video 1/1 (12/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 106.2ms\n",
      "video 1/1 (13/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 93.5ms\n",
      "video 1/1 (14/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 96.3ms\n",
      "video 1/1 (15/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 101.9ms\n",
      "video 1/1 (16/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 104.9ms\n",
      "video 1/1 (17/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 98.7ms\n",
      "video 1/1 (18/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 93.0ms\n",
      "video 1/1 (19/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 106.2ms\n",
      "video 1/1 (20/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 18 cars, 1 bus, 1 truck, 90.5ms\n",
      "video 1/1 (21/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 18 cars, 1 bus, 1 truck, 95.4ms\n",
      "video 1/1 (22/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 18 cars, 1 bus, 1 truck, 102.8ms\n",
      "video 1/1 (23/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 19 cars, 1 bus, 1 truck, 103.9ms\n",
      "video 1/1 (24/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 92.0ms\n",
      "video 1/1 (25/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 150.7ms\n",
      "video 1/1 (26/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 97.3ms\n",
      "video 1/1 (27/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 2 trucks, 103.3ms\n",
      "video 1/1 (28/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 2 trucks, 101.6ms\n",
      "video 1/1 (29/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 2 trucks, 102.5ms\n",
      "video 1/1 (30/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 88.2ms\n",
      "video 1/1 (31/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 90.2ms\n",
      "video 1/1 (32/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 truck, 100.0ms\n",
      "video 1/1 (33/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 120.1ms\n",
      "video 1/1 (34/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 111.5ms\n",
      "video 1/1 (35/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 12 cars, 1 bus, 1 truck, 83.8ms\n",
      "video 1/1 (36/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 82.5ms\n",
      "video 1/1 (37/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 99.0ms\n",
      "video 1/1 (38/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 80.7ms\n",
      "video 1/1 (39/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 86.9ms\n",
      "video 1/1 (40/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 78.0ms\n",
      "video 1/1 (41/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 81.6ms\n",
      "video 1/1 (42/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 77.6ms\n",
      "video 1/1 (43/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 78.2ms\n",
      "video 1/1 (44/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 82.4ms\n",
      "video 1/1 (45/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 84.1ms\n",
      "video 1/1 (46/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 86.3ms\n",
      "video 1/1 (47/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 82.3ms\n",
      "video 1/1 (48/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 86.2ms\n",
      "video 1/1 (49/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 83.0ms\n",
      "video 1/1 (50/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 13 cars, 1 bus, 1 truck, 83.3ms\n",
      "video 1/1 (51/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 97.9ms\n",
      "video 1/1 (52/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 84.6ms\n",
      "video 1/1 (53/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 84.8ms\n",
      "video 1/1 (54/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 80.5ms\n",
      "video 1/1 (55/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 85.2ms\n",
      "video 1/1 (56/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 88.2ms\n",
      "video 1/1 (57/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 83.6ms\n",
      "video 1/1 (58/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 97.7ms\n",
      "video 1/1 (59/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 108.8ms\n",
      "video 1/1 (60/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 120.4ms\n",
      "video 1/1 (61/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 130.4ms\n",
      "video 1/1 (62/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 133.6ms\n",
      "video 1/1 (63/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 143.5ms\n",
      "video 1/1 (64/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 151.5ms\n",
      "video 1/1 (65/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 153.6ms\n",
      "video 1/1 (66/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 155.9ms\n",
      "video 1/1 (67/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 155.6ms\n",
      "video 1/1 (68/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 163.4ms\n",
      "video 1/1 (69/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 167.8ms\n",
      "video 1/1 (70/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 159.5ms\n",
      "video 1/1 (71/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 159.1ms\n",
      "video 1/1 (72/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 18 cars, 1 bus, 1 truck, 168.9ms\n",
      "video 1/1 (73/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 1 truck, 164.5ms\n",
      "video 1/1 (74/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 19 cars, 1 bus, 1 truck, 160.2ms\n",
      "video 1/1 (75/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 150.3ms\n",
      "video 1/1 (76/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 19 cars, 1 truck, 169.1ms\n",
      "video 1/1 (77/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 19 cars, 1 truck, 160.3ms\n",
      "video 1/1 (78/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 163.2ms\n",
      "video 1/1 (79/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 148.7ms\n",
      "video 1/1 (80/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 149.9ms\n",
      "video 1/1 (81/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 171.5ms\n",
      "video 1/1 (82/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 153.8ms\n",
      "video 1/1 (83/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 154.8ms\n",
      "video 1/1 (84/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 18 cars, 1 truck, 142.9ms\n",
      "video 1/1 (85/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 truck, 147.6ms\n",
      "video 1/1 (86/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 truck, 179.9ms\n",
      "video 1/1 (87/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 truck, 156.5ms\n",
      "video 1/1 (88/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 truck, 151.0ms\n",
      "video 1/1 (89/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 truck, 184.5ms\n",
      "video 1/1 (90/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 truck, 203.7ms\n",
      "video 1/1 (91/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 truck, 156.7ms\n",
      "video 1/1 (92/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 177.2ms\n",
      "video 1/1 (93/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 truck, 182.9ms\n",
      "video 1/1 (94/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 175.0ms\n",
      "video 1/1 (95/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 157.1ms\n",
      "video 1/1 (96/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 1 truck, 150.2ms\n",
      "video 1/1 (97/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 153.9ms\n",
      "video 1/1 (98/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 159.6ms\n",
      "video 1/1 (99/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 144.5ms\n",
      "video 1/1 (100/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 154.2ms\n",
      "video 1/1 (101/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 146.1ms\n",
      "video 1/1 (102/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 146.5ms\n",
      "video 1/1 (103/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 150.4ms\n",
      "video 1/1 (104/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 142.5ms\n",
      "video 1/1 (105/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 151.7ms\n",
      "video 1/1 (106/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 288.7ms\n",
      "video 1/1 (107/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 truck, 193.2ms\n",
      "video 1/1 (108/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 truck, 157.0ms\n",
      "video 1/1 (109/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 truck, 167.9ms\n",
      "video 1/1 (110/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 truck, 158.6ms\n",
      "video 1/1 (111/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 truck, 146.3ms\n",
      "video 1/1 (112/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 truck, 145.0ms\n",
      "video 1/1 (113/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 145.5ms\n",
      "video 1/1 (114/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 149.5ms\n",
      "video 1/1 (115/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 142.1ms\n",
      "video 1/1 (116/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 133.5ms\n",
      "video 1/1 (117/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 1 truck, 148.7ms\n",
      "video 1/1 (118/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 149.2ms\n",
      "video 1/1 (119/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 147.6ms\n",
      "video 1/1 (120/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 144.9ms\n",
      "video 1/1 (121/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 152.4ms\n",
      "video 1/1 (122/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 161.2ms\n",
      "video 1/1 (123/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 bus, 171.3ms\n",
      "video 1/1 (124/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 165.4ms\n",
      "video 1/1 (125/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 166.3ms\n",
      "video 1/1 (126/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 bus, 162.7ms\n",
      "video 1/1 (127/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 146.8ms\n",
      "video 1/1 (128/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 17 cars, 1 bus, 157.4ms\n",
      "video 1/1 (129/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 187.0ms\n",
      "video 1/1 (130/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 14 cars, 1 bus, 1 truck, 154.7ms\n",
      "video 1/1 (131/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 185.9ms\n",
      "video 1/1 (132/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 1 truck, 170.4ms\n",
      "video 1/1 (133/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 175.9ms\n",
      "video 1/1 (134/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 165.9ms\n",
      "video 1/1 (135/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 188.2ms\n",
      "video 1/1 (136/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 16 cars, 188.6ms\n",
      "video 1/1 (137/137) d:\\study\\computer_vision\\speechcam_detection\\yolov8\\..\\data\\numper_plates.mp4: 384x640 15 cars, 1 truck, 176.0ms\n",
      "Speed: 2.5ms preprocess, 132.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model(source=\"../data/numper_plates.mp4\", show=True, conf=0.4, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
