{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Tạo ba bộ phân đoạn nền sử dụng ba thuật toán khác nhau\n",
    "# fgbg1 = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "fgbg2 = cv2.createBackgroundSubtractorMOG2()\n",
    "# fgbg3 = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "\n",
    "# Mở video từ tệp tin (thay 'ten_file_video.mp4' bằng đường dẫn đến tệp video của bạn)\n",
    "cap = cv2.VideoCapture('../speechcam_detection/data/speech_cars.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Áp dụng mask cho phân đoạn nền\n",
    "    # fgmask1 = fgbg1.apply(frame)\n",
    "    fgmask2 = fgbg2.apply(frame)\n",
    "    # fgmask3 = fgbg3.apply(frame)\n",
    "\n",
    "    # Hiển thị video gốc và kết quả phân đoạn nền sử dụng ba thuật toán\n",
    "    cv2.imshow('Original', frame)\n",
    "    # cv2.imshow('MOG', fgmask1)\n",
    "    cv2.imshow('MOG2', fgmask2)\n",
    "    # cv2.imshow('GMG', fgmask3)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def absolute_difference(frame1, frame2):\n",
    "    if frame1.shape[-1] == 3:\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    if frame2.shape[-1] == 3:\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = np.abs(frame1 - frame2)\n",
    "    return frame_diff\n",
    "\n",
    "# Mở video từ tệp tin\n",
    "cap = cv2.VideoCapture('D:/study/CV/CK/CV_CK/speechcam_detection/data/speech_cars.mp4')\n",
    "\n",
    "# Đọc khung hình đầu tiên\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    exit()\n",
    "frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Sử dụng hàm absolute_difference để tính toán sự khác biệt tuyệt đối\n",
    "    frame_diff = absolute_difference(frame1, frame2)\n",
    "\n",
    "    # Hiển thị kết quả\n",
    "    cv2.imshow('Absolute Difference', frame_diff)\n",
    "\n",
    "    frame1 = frame2\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # 27 là mã ASCII của phím ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc video từ một tệp\n",
    "video_capture =cv2.VideoCapture('../speechcam_detection/data/traffic_1.mp4')\n",
    "\n",
    "\n",
    "# Khởi tạo kernel cho phép mở rộng (structuring element)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Chuyển đổi hình ảnh sang grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Áp dụng Top-hat filter\n",
    "    top_hat = cv2.morphologyEx(gray_frame, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    # Hiển thị hình ảnh gốc và kết quả Top-hat filter\n",
    "    cv2.imshow('Original', gray_frame)\n",
    "    cv2.imshow('Top-Hat Filter', top_hat)\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == 57:  # Ấn Esc để thoát\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def custom_top_hat_filter(image, kernel_size):\n",
    "    # Chuyển đổi hình ảnh sang grayscale nếu nó chưa ở dạng grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = image\n",
    "\n",
    "    # Khởi tạo kernel cho phép mở rộng (structuring element)\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "\n",
    "    # Áp dụng phép toán mở rộng\n",
    "    eroded = cv2.erode(gray_image, kernel, iterations=1)\n",
    "\n",
    "    # Trừ hình ảnh mở rộng từ hình ảnh grayscale gốc\n",
    "    top_hat = gray_image - eroded\n",
    "\n",
    "    return top_hat\n",
    "\n",
    "# Đọc video từ một tệp\n",
    "video_capture  =cv2.VideoCapture('../speechcam_detection/data/traffic_1.mp4')\n",
    "\n",
    "\n",
    "# Kích thước mong muốn cho khung hình\n",
    "desired_size = (700,550)\n",
    "kernel_size=(5, 5)\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Áp dụng Top-hat filter bằng cách gọi hàm custom_top_hat_filter\n",
    "    top_hat = custom_top_hat_filter(frame,kernel_size)\n",
    "\n",
    "    # Thay đổi kích thước ảnh Top-hat\n",
    "    top_hat_resized = cv2.resize(top_hat, desired_size)\n",
    "    frame = cv2.resize(frame,desired_size)\n",
    "\n",
    "    # Hiển thị hình ảnh gốc và kết quả Top-hat filter\n",
    "    cv2.imshow('Original', frame)\n",
    "    cv2.imshow('Custom Top-Hat Filter', top_hat_resized)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Ấn Esc để thoát\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\CV\\CK\\CV_CK\\code\\background_sub.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Break the loop if we've reached the end of the video\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m tribolium \u001b[39m=\u001b[39m frame  \u001b[39m# Assuming tribolium is the frame you want to process\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m minimum_trib \u001b[39m=\u001b[39m ndimage\u001b[39m.\u001b[39;49mminimum_filter(tribolium, size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m orig_sub_min \u001b[39m=\u001b[39m tribolium \u001b[39m-\u001b[39m minimum_trib\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Visualize the result\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\duyen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1283\u001b[0m, in \u001b[0;36mminimum_filter\u001b[1;34m(input, size, footprint, output, mode, cval, origin, axes)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[39m@_ni_docstrings\u001b[39m\u001b[39m.\u001b[39mdocfiller\n\u001b[0;32m   1240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimum_filter\u001b[39m(\u001b[39minput\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, footprint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1241\u001b[0m                    mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreflect\u001b[39m\u001b[39m\"\u001b[39m, cval\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, origin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m, axes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1242\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calculate a multidimensional minimum filter.\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m \n\u001b[0;32m   1244\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m    >>> plt.show()\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     \u001b[39mreturn\u001b[39;00m _min_or_max_filter(\u001b[39minput\u001b[39;49m, size, footprint, \u001b[39mNone\u001b[39;49;00m, output, mode,\n\u001b[0;32m   1284\u001b[0m                               cval, origin, \u001b[39m1\u001b[39;49m, axes)\n",
      "File \u001b[1;32mc:\\Users\\duyen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1195\u001b[0m, in \u001b[0;36m_min_or_max_filter\u001b[1;34m(input, size, footprint, structure, output, mode, cval, origin, minimum, axes)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(axes) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1194\u001b[0m     \u001b[39mfor\u001b[39;00m axis, size, origin, mode \u001b[39min\u001b[39;00m axes:\n\u001b[1;32m-> 1195\u001b[0m         filter_(\u001b[39minput\u001b[39;49m, \u001b[39mint\u001b[39;49m(size), axis, output, mode, cval, origin)\n\u001b[0;32m   1196\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m output\n\u001b[0;32m   1197\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\duyen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1084\u001b[0m, in \u001b[0;36mminimum_filter1d\u001b[1;34m(input, size, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid origin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1083\u001b[0m mode \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m-> 1084\u001b[0m _nd_image\u001b[39m.\u001b[39;49mmin_or_max_filter1d(\u001b[39minput\u001b[39;49m, size, axis, output, mode, cval,\n\u001b[0;32m   1085\u001b[0m                               origin, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1086\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "# Open the video file using OpenCV\n",
    "video_capture = cv2.VideoCapture('../speechcam_detection/data/traffic_1.mp4')\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "size = 25  # Setting the size of the minimum filter to be larger than the nuclei\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    tribolium = frame  # Assuming tribolium is the frame you want to process\n",
    "\n",
    "    minimum_trib = ndimage.minimum_filter(tribolium, size)\n",
    "    orig_sub_min = tribolium - minimum_trib\n",
    "\n",
    "    # Visualize the result\n",
    "    cv2.imshow('Original', tribolium)\n",
    "    cv2.imshow('Original - Minimum', orig_sub_min)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "video_capture.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.filters import threshold_local\n",
    "import tensorflow as tf\n",
    "from skimage import measure\n",
    "import imutils\n",
    "import os\n",
    "\n",
    "def sort_cont(character_contours):\n",
    "    \"\"\"\n",
    "    Sắp xếp các đường viền (contours).\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in character_contours]\n",
    "\n",
    "    (character_contours, boundingBoxes) = zip(*sorted(zip(character_contours,\n",
    "                                                        boundingBoxes),\n",
    "                                                    key = lambda b: b[1][i],\n",
    "                                                    reverse = False))\n",
    "\n",
    "    return character_contours\n",
    "\n",
    "def segment_chars(plate_img, fixed_width):\n",
    "    \"\"\"\n",
    "    Trích xuất kênh giá trị (Value channel) từ không gian màu HSV\n",
    "    của hình ảnh và áp dụng ngưỡng th adapt để hiển thị ký tự trên biển số xe.\n",
    "    \"\"\"\n",
    "    V = cv2.split(cv2.cvtColor(plate_img, cv2.COLOR_BGR2HSV))[2]\n",
    "\n",
    "    thresh = cv2.adaptiveThreshold(V, 255,\n",
    "                                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY,\n",
    "                                11, 2)\n",
    "\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # Thay đổi kích thước vùng biển số xe về kích thước cố định\n",
    "    plate_img = imutils.resize(plate_img, width=fixed_width)\n",
    "    thresh = imutils.resize(thresh, width=fixed_width)\n",
    "    bgr_thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Thực hiện phân tích thành phần nối tiếp và khởi tạo mặt nạ để lưu trữ vị trí\n",
    "    # các ứng viên ký tự\n",
    "    labels = measure.label(thresh, background=0)\n",
    "    charCandidates = np.zeros(thresh.shape, dtype='uint8')\n",
    "\n",
    "    # Duyệt qua các thành phần duy nhất\n",
    "    characters = []\n",
    "    for label in np.unique(labels):\n",
    "\n",
    "        # Nếu đây là nhãn nền, bỏ qua\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # Ngược lại, xây dựng mặt nạ nhãn để hiển thị\n",
    "        # chỉ các thành phần kết nối cho nhãn hiện tại,\n",
    "        # sau đó tìm các đường viền trong mặt nạ nhãn\n",
    "        labelMask = np.zeros(thresh.shape, dtype='uint8')\n",
    "        labelMask[labels == label] = 255\n",
    "        cnts = cv2.findContours(labelMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts = cnts[1] if imutils.is_cv3() else cnts[0]\n",
    "\n",
    "        # Đảm bảo rằng ít nhất có một đường viền được tìm thấy trong mặt nạ\n",
    "        if len(cnts) > 0:\n",
    "            # Lấy đường viền lớn nhất tương ứng\n",
    "            # với thành phần trong mặt nạ, sau đó lấy khung hình cho đường viền đó\n",
    "            c = max(cnts, key=cv2.contourArea)\n",
    "            (boxX, boxY, boxW, boxH) = cv2.boundingRect(c)\n",
    "\n",
    "            # Tính tỷ lệ khía cạnh, tính kín đáo và\n",
    "            # tỷ lệ chiều cao của thành phần\n",
    "            aspectRatio = boxW / float(boxH)\n",
    "            solidity = cv2.contourArea(c) / float(boxW * boxH)\n",
    "            heightRatio = boxH / float(plate_img.shape[0])\n",
    "\n",
    "            # Xác định xem tỷ lệ khía cạnh, tính kín đáo\n",
    "            # và chiều cao của đường viền có đáp ứng\n",
    "            # các kiểm tra hay không\n",
    "            keepAspectRatio = aspectRatio < 1.0\n",
    "            keepSolidity = solidity > 0.15\n",
    "            keepHeight = heightRatio > 0.5 and heightRatio < 0.95\n",
    "\n",
    "            # Kiểm tra xem thành phần có đáp ứng tất cả các kiểm tra hay không\n",
    "            if keepAspectRatio and keepSolidity and keepHeight and boxW > 14:\n",
    "                # Tính lớp vỏ lớn nhất của đường viền và vẽ nó trên mặt nạ ứng viên ký tự\n",
    "                hull = cv2.convexHull(c)\n",
    "                cv2.drawContours(charCandidates, [hull], -1, 255, -1)\n",
    "\n",
    "    contours, hier = cv2.findContours(charCandidates, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        contours = sort_cont(contours)\n",
    "\n",
    "        # Giá trị để thêm vào mỗi chiều của ký tự\n",
    "        addPixel = 4\n",
    "        for c in contours:\n",
    "            (x, y, w, h) = cv2.boundingRect(c)\n",
    "            if y > addPixel:\n",
    "                y = y - addPixel\n",
    "            else:\n",
    "                y = 0\n",
    "            if x > addPixel:\n",
    "                x = x - addPixel\n",
    "            else:\n",
    "                x = 0\n",
    "            temp = bgr_thresh[y:y + h + (addPixel * 2), x:x + w + (addPixel * 2)]\n",
    "            characters.append(temp)\n",
    "\n",
    "        return characters\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "class PlateFinder:\n",
    "    def __init__(self, minPlateArea, maxPlateArea):\n",
    "        # Diện tích tối thiểu của biển số xe\n",
    "        self.min_area = minPlateArea\n",
    "        # Diện tích tối đa của biển số xe\n",
    "        self.max_area = maxPlateArea \n",
    "        self.element_structure = cv2.getStructuringElement(shape=cv2.MORPH_RECT, ksize=(22, 3))\n",
    "\n",
    "    def preprocess(self, input_img):\n",
    "        imgBlurred = cv2.GaussianBlur(input_img, (7, 7), 0)\n",
    "        # Chuyển đổi sang ảnh xám\n",
    "        gray = cv2.cvtColor(imgBlurred, cv2.COLOR_BGR2GRAY)\n",
    "        # Sử dụng sobelX để lấy cạnh dọc\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_8U, 1, 0, ksize=3) \n",
    "        # Ngưỡng Otsu\n",
    "        ret2, threshold_img = cv2.threshold(sobelx, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        element = self.element_structure\n",
    "        morph_n_thresholded_img = threshold_img.copy()\n",
    "        cv2.morphologyEx(src=threshold_img, op=cv2.MORPH_CLOSE, kernel=element, dst=morph_n_thresholded_img)\n",
    "        return morph_n_thresholded_img\n",
    "\n",
    "    def extract_contours(self, after_preprocess):\n",
    "        contours, _ = cv2.findContours(after_preprocess, mode=cv2.RETR_EXTERNAL, method=cv2.CHAIN_APPROX_NONE)\n",
    "        return contours\n",
    "\n",
    "    def clean_plate(self, plate):\n",
    "        gray = cv2.cvtColor(plate, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "        if contours:\n",
    "            areas = [cv2.contourArea(c) for c in contours]\n",
    "            max_index = np.argmax(areas) \n",
    "            max_cnt = contours[max_index]\n",
    "            max_cntArea = areas[max_index]\n",
    "            x, y, w, h = cv2.boundingRect(max_cnt)\n",
    "            rect = cv2.minAreaRect(max_cnt)\n",
    "            if not self.ratioCheck(max_cntArea, plate.shape[1], plate.shape[0]):\n",
    "                return plate, False, None\n",
    "            return plate, True, [x, y, w, h]\n",
    "        else:\n",
    "            return plate, False, None\n",
    "\n",
    "    def check_plate(self, input_img, contour):\n",
    "        min_rect = cv2.minAreaRect(contour)\n",
    "        if self.validateRatio(min_rect):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            after_validation_img = input_img[y:y + h, x:x + w]\n",
    "            after_clean_plate_img, plateFound, coordinates = self.clean_plate(after_validation_img)\n",
    "            if plateFound:\n",
    "                characters_on_plate = self.find_characters_on_plate(after_clean_plate_img)\n",
    "                if (characters_on_plate is not None and len(characters_on_plate) == 8):\n",
    "                    x1, y1, w1, h1 = coordinates\n",
    "                    coordinates = x1 + x, y1 + y\n",
    "                    after_check_plate_img = after_clean_plate_img\n",
    "                    return after_check_plate_img, characters_on_plate, coordinates\n",
    "        return None, None, None\n",
    "\n",
    "    def find_possible_plates(self, input_img):\n",
    "        plates = []\n",
    "        self.char_on_plate = []\n",
    "        self.corresponding_area = []\n",
    "        self.after_preprocess = self.preprocess(input_img)\n",
    "        possible_plate_contours = self.extract_contours(self.after_preprocess)\n",
    "        for cnts in possible_plate_contours:\n",
    "            plate, characters_on_plate, coordinates = self.check_plate(input_img, cnts)\n",
    "            if plate is not None:\n",
    "                plates.append(plate)\n",
    "                self.char_on_plate.append(characters_on_plate)\n",
    "                self.corresponding_area.append(coordinates)\n",
    "        if (len(plates) > 0):\n",
    "            return plates\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def find_characters_on_plate(self, plate):\n",
    "        charactersFound = segment_chars(plate, 400)\n",
    "        if charactersFound:\n",
    "            return charactersFound\n",
    "\n",
    "    def ratioCheck(self, area, width, height):\n",
    "        min = self.min_area\n",
    "        max = self.max_area\n",
    "        ratioMin = 3\n",
    "        ratioMax = 6\n",
    "        ratio = float(width) / float(height)\n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def preRatioCheck(self, area, width, height):\n",
    "        min = self.min_area\n",
    "        max = self.max_area\n",
    "        ratioMin = 2.5\n",
    "        ratioMax = 7\n",
    "        ratio = float(width) / float(height)\n",
    "        if ratio < 1:\n",
    "            ratio = 1 / ratio\n",
    "        if (area < min or area > max) or (ratio < ratioMin or ratio > ratioMax):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def validateRatio(self, rect):\n",
    "        (x, y), (width, height), rect_angle = rect\n",
    "        if (width > height):\n",
    "            angle = -rect_angle\n",
    "        else:\n",
    "            angle = 90 + rect_angle\n",
    "        if angle > 15:\n",
    "            return False\n",
    "        if (height == 0 or width == 0):\n",
    "            return False\n",
    "        area = width * height\n",
    "        if not self.preRatioCheck(area, width, height):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
