{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Tạo ba bộ phân đoạn nền sử dụng ba thuật toán khác nhau\n",
    "# fgbg1 = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "fgbg2 = cv2.createBackgroundSubtractorMOG2()\n",
    "# fgbg3 = cv2.bgsegm.createBackgroundSubtractorGMG()\n",
    "\n",
    "# Mở video từ tệp tin (thay 'ten_file_video.mp4' bằng đường dẫn đến tệp video của bạn)\n",
    "cap = cv2.VideoCapture('D:/study/CV/CK/CV_CK/speechcam_detection/data/speech_cars.mp4')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Áp dụng mask cho phân đoạn nền\n",
    "    # fgmask1 = fgbg1.apply(frame)\n",
    "    fgmask2 = fgbg2.apply(frame)\n",
    "    # fgmask3 = fgbg3.apply(frame)\n",
    "\n",
    "    # Hiển thị video gốc và kết quả phân đoạn nền sử dụng ba thuật toán\n",
    "    cv2.imshow('Original', frame)\n",
    "    # cv2.imshow('MOG', fgmask1)\n",
    "    cv2.imshow('MOG2', fgmask2)\n",
    "    # cv2.imshow('GMG', fgmask3)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def absolute_difference(frame1, frame2):\n",
    "    if frame1.shape[-1] == 3:\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    if frame2.shape[-1] == 3:\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    frame_diff = np.abs(frame1 - frame2)\n",
    "    return frame_diff\n",
    "\n",
    "# Mở video từ tệp tin\n",
    "cap = cv2.VideoCapture('D:/study/CV/CK/CV_CK/speechcam_detection/data/speech_cars.mp4')\n",
    "\n",
    "# Đọc khung hình đầu tiên\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    exit()\n",
    "frame1_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Sử dụng hàm absolute_difference để tính toán sự khác biệt tuyệt đối\n",
    "    frame_diff = absolute_difference(frame1, frame2)\n",
    "\n",
    "    # Hiển thị kết quả\n",
    "    cv2.imshow('Absolute Difference', frame_diff)\n",
    "\n",
    "    frame1 = frame2\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == 27:  # 27 là mã ASCII của phím ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Đọc video từ một tệp\n",
    "video_capture =cv2.VideoCapture('../speechcam_detection/data/traffic_1.mp4')\n",
    "\n",
    "\n",
    "# Khởi tạo kernel cho phép mở rộng (structuring element)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Chuyển đổi hình ảnh sang grayscale\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Áp dụng Top-hat filter\n",
    "    top_hat = cv2.morphologyEx(gray_frame, cv2.MORPH_TOPHAT, kernel)\n",
    "\n",
    "    # Hiển thị hình ảnh gốc và kết quả Top-hat filter\n",
    "    cv2.imshow('Original', gray_frame)\n",
    "    cv2.imshow('Top-Hat Filter', top_hat)\n",
    "\n",
    "    if cv2.waitKey(0) & 0xFF == 57:  # Ấn Esc để thoát\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def custom_top_hat_filter(image, kernel_size):\n",
    "    # Chuyển đổi hình ảnh sang grayscale nếu nó chưa ở dạng grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_image = image\n",
    "\n",
    "    # Khởi tạo kernel cho phép mở rộng (structuring element)\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "\n",
    "    # Áp dụng phép toán mở rộng\n",
    "    eroded = cv2.erode(gray_image, kernel, iterations=1)\n",
    "\n",
    "    # Trừ hình ảnh mở rộng từ hình ảnh grayscale gốc\n",
    "    top_hat = gray_image - eroded\n",
    "\n",
    "    return top_hat\n",
    "\n",
    "# Đọc video từ một tệp\n",
    "video_capture  =cv2.VideoCapture('../speechcam_detection/data/traffic_1.mp4')\n",
    "\n",
    "\n",
    "# Kích thước mong muốn cho khung hình\n",
    "desired_size = (700,550)\n",
    "kernel_size=(5, 5)\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Áp dụng Top-hat filter bằng cách gọi hàm custom_top_hat_filter\n",
    "    top_hat = custom_top_hat_filter(frame,kernel_size)\n",
    "\n",
    "    # Thay đổi kích thước ảnh Top-hat\n",
    "    top_hat_resized = cv2.resize(top_hat, desired_size)\n",
    "    frame = cv2.resize(frame,desired_size)\n",
    "\n",
    "    # Hiển thị hình ảnh gốc và kết quả Top-hat filter\n",
    "    cv2.imshow('Original', frame)\n",
    "    cv2.imshow('Custom Top-Hat Filter', top_hat_resized)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # Ấn Esc để thoát\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\study\\CV\\CK\\CV_CK\\code\\background_sub.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Break the loop if we've reached the end of the video\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m tribolium \u001b[39m=\u001b[39m frame  \u001b[39m# Assuming tribolium is the frame you want to process\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m minimum_trib \u001b[39m=\u001b[39m ndimage\u001b[39m.\u001b[39;49mminimum_filter(tribolium, size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m orig_sub_min \u001b[39m=\u001b[39m tribolium \u001b[39m-\u001b[39m minimum_trib\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study/CV/CK/CV_CK/code/background_sub.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Visualize the result\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\duyen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1283\u001b[0m, in \u001b[0;36mminimum_filter\u001b[1;34m(input, size, footprint, output, mode, cval, origin, axes)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[39m@_ni_docstrings\u001b[39m\u001b[39m.\u001b[39mdocfiller\n\u001b[0;32m   1240\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimum_filter\u001b[39m(\u001b[39minput\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, footprint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1241\u001b[0m                    mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreflect\u001b[39m\u001b[39m\"\u001b[39m, cval\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, origin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m, axes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1242\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Calculate a multidimensional minimum filter.\u001b[39;00m\n\u001b[0;32m   1243\u001b[0m \n\u001b[0;32m   1244\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[39m    >>> plt.show()\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     \u001b[39mreturn\u001b[39;00m _min_or_max_filter(\u001b[39minput\u001b[39;49m, size, footprint, \u001b[39mNone\u001b[39;49;00m, output, mode,\n\u001b[0;32m   1284\u001b[0m                               cval, origin, \u001b[39m1\u001b[39;49m, axes)\n",
      "File \u001b[1;32mc:\\Users\\duyen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1195\u001b[0m, in \u001b[0;36m_min_or_max_filter\u001b[1;34m(input, size, footprint, structure, output, mode, cval, origin, minimum, axes)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(axes) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1194\u001b[0m     \u001b[39mfor\u001b[39;00m axis, size, origin, mode \u001b[39min\u001b[39;00m axes:\n\u001b[1;32m-> 1195\u001b[0m         filter_(\u001b[39minput\u001b[39;49m, \u001b[39mint\u001b[39;49m(size), axis, output, mode, cval, origin)\n\u001b[0;32m   1196\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m output\n\u001b[0;32m   1197\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\duyen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:1084\u001b[0m, in \u001b[0;36mminimum_filter1d\u001b[1;34m(input, size, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid origin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1083\u001b[0m mode \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m-> 1084\u001b[0m _nd_image\u001b[39m.\u001b[39;49mmin_or_max_filter1d(\u001b[39minput\u001b[39;49m, size, axis, output, mode, cval,\n\u001b[0;32m   1085\u001b[0m                               origin, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m   1086\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "# Open the video file using OpenCV\n",
    "video_capture = cv2.VideoCapture('../speechcam_detection/data/traffic_1.mp4')\n",
    "\n",
    "# Check if the video file was opened successfully\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "size = 25  # Setting the size of the minimum filter to be larger than the nuclei\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    if not ret:\n",
    "        break  # Break the loop if we've reached the end of the video\n",
    "\n",
    "    tribolium = frame  # Assuming tribolium is the frame you want to process\n",
    "\n",
    "    minimum_trib = ndimage.minimum_filter(tribolium, size)\n",
    "    orig_sub_min = tribolium - minimum_trib\n",
    "\n",
    "    # Visualize the result\n",
    "    cv2.imshow('Original', tribolium)\n",
    "    cv2.imshow('Original - Minimum', orig_sub_min)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "video_capture.release()\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
